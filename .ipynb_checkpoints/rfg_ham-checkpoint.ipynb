{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c23ff81b-24f8-4ef3-99c9-d9a9df5f15b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98ac1ef5-00b7-46ad-a514-f31470713884",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfg_ham = pd.read_excel('/Users/fuqiaozhi/Desktop/UTD Semesters/Spring 2024/BUAN 6337/Conagra Data/Data/Rfg Ham_POS_2020.xlsx')\n",
    "rfg_ham2 = pd.read_excel('/Users/fuqiaozhi/Desktop/UTD Semesters/Spring 2024/BUAN 6337/Conagra Data/Data/Rfg Ham_POS_2021.xlsx')\n",
    "rfg_ham3 = pd.read_excel('/Users/fuqiaozhi/Desktop/UTD Semesters/Spring 2024/BUAN 6337/Conagra Data/Data/Rfg Ham_POS_2022.xlsx')\n",
    "rfg_ham4 = pd.read_excel('/Users/fuqiaozhi/Desktop/UTD Semesters/Spring 2024/BUAN 6337/Conagra Data/Data/Rfg Ham_POS_2023.xlsx')\n",
    "rfg_ham5 = pd.read_excel('/Users/fuqiaozhi/Desktop/UTD Semesters/Spring 2024/BUAN 6337/Conagra Data/Data/Rfg Ham_POS_2024.xlsx')\n",
    "product_attribute = pd.read_excel('/Users/fuqiaozhi/Desktop/UTD Semesters/Spring 2024/BUAN 6337/Conagra Cleaned Data/Product Attributes.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26f4ce6a-c5ca-4d16-839a-fd2c7296b05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation\n",
    "def imputation_process(row):\n",
    "    row['Incremental Units'] = row['Unit Sales'] - row['Base Unit Sales']\n",
    "    row['Incremental Volume'] = row['Volume Sales'] - row['Base Volume Sales']\n",
    "    row['Incremental Dollars'] = row['Dollar Sales'] - row['Base Dollar Sales']\n",
    "    return row\n",
    "\n",
    "# Split Geography column and only save its location\n",
    "def extract_location(col):\n",
    "    return col.split(' - ')[0]\n",
    "\n",
    "# convert time into year month and day\n",
    "def parse_time(col):\n",
    "    # Year, month, day\n",
    "    sep_data = col.split('-')\n",
    "    year = int('20' + sep_data[2])\n",
    "    month = int(sep_data[0][-2:])\n",
    "    day = int(sep_data[1])\n",
    "    # Quarter of given date\n",
    "    quarter = (month - 1) // 3 + 1\n",
    "    return pd.Series([year, quarter, month], index = ['Year', 'Quarter', 'Month'])\n",
    "\n",
    "# Split product column and only save company name and product name\n",
    "def parse_product(col):  \n",
    "    return col.split(' - ')[0]\n",
    "\n",
    "\n",
    "# Based on length of company name, select product name\n",
    "def extract_product_name(full_string, brand_name):\n",
    "    brand_name_length = len(brand_name)\n",
    "    words = full_string[brand_name_length:].strip()\n",
    "    return words\n",
    "\n",
    "# # Arrange columns order\n",
    "def change_column_order(df):\n",
    "    final_order = [\n",
    "        'Geography', 'Year', 'Quarter', 'Manufacturer Name',\n",
    "        'Brand Name', 'Product Name', 'Flavor / Scent', 'Meat Source',\n",
    "        'Unit Sales', 'Volume Sales', 'Dollar Sales', 'Price per Unit', \n",
    "        'Price per Volume', 'Base Unit Sales', 'Base Volume Sales', 'Base Dollar Sales',\n",
    "        'Incremental Units', 'Incremental Volume', 'Incremental Dollars', \n",
    "        'ACV Weighted Distribution'\n",
    "    ]\n",
    "    return df[final_order]\n",
    "\n",
    "def merge_content(df1, df2):\n",
    "    combined = df1.merge(df2, how = 'left', on = 'Product')\n",
    "    return combined\n",
    "\n",
    "def map_season(month):\n",
    "    # Northern Hemisphere standard mapping\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'Winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Summer'\n",
    "    elif month in [9, 10, 11]:\n",
    "        return 'Fall'\n",
    "\n",
    "\n",
    "# Full tranform process\n",
    "def transform_data(df, df2):\n",
    "    table1 = merge_content(df, df2)\n",
    "    # Used customized function\n",
    "    table1['Geography'] = table1['Geography'].map(extract_location)\n",
    "    table1[['Year', 'Quarter', 'Month']] = table1['Time'].apply(parse_time)\n",
    "    table1['Product'] = table1['Product'].map(parse_product)\n",
    "    table1['Product Name'] = table1.apply(lambda row: extract_product_name(row['Product'], row['Brand Name']), axis=1)\n",
    "    #df['Product Name'] = df.apply(extract_product_name(df['Product'], df['Brand']), axis = 1)\n",
    "    \n",
    "    # Mapping quarter to seasonality\n",
    "    table1['Season'] = table1['Month'].apply(map_season)\n",
    "    # Change column order\n",
    "    transformed = change_column_order(table1).apply(imputation_process, axis = 1)\n",
    "    return transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d717df1-8a48-44b0-8764-882748e08961",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfg_ham_2020 = transform_data(rfg_ham, product_attribute)\n",
    "rfg_ham_2021 = transform_data(rfg_ham2, product_attribute)\n",
    "rfg_ham_2022 = transform_data(rfg_ham3, product_attribute)\n",
    "rfg_ham_2023 = transform_data(rfg_ham4, product_attribute)\n",
    "rfg_ham_2024 = transform_data(rfg_ham5, product_attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1158cbfc-7bec-45b4-a41c-1e1f050b7a4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combined & export\n",
    "full_rfg_ham = pd.concat([rfg_ham_2020, rfg_ham_2021, rfg_ham_2022, rfg_ham_2023, rfg_ham_2024])\n",
    "output_file = '/Users/fuqiaozhi/Desktop/UTD Semesters/Spring 2024/BUAN 6337/full_rfg_ham.csv'\n",
    "full_rfg_ham.to_csv(output_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
